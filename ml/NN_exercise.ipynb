{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ca36ea-4c36-4f54-bdfc-f56e2941397f",
   "metadata": {},
   "source": [
    "# Try it Yourself!\n",
    "\n",
    "- Using the MPRester API find 2 element oxides that are stable. Sample at least 5 different properties including band gap. Don't forget to clean the data!\n",
    "- If the band gap is between 0.5-3 then change the value to 1 to signifiy a semiconductor. If it's outside that range change the value to 0 to signify it's not a semiconductor (a metal or insulator).\n",
    "- Set up a NN to classify if something is a semiconductor or not. Make sure to create a train test split for validation!\n",
    "- Perform hyperparameter tuning on the model and compare the performance from pre-tuning to post-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11edd09e-bf61-4f73-be42-f22d9e7d4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from mp_api.client import MPRester\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from mp_api.client import MPRester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a41765-92f0-43f1-b791-67ac07ea96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "filename = r'api.txt'\n",
    "\n",
    "def get_file_contents(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)\n",
    "        \n",
    "api_key=get_file_contents(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05008480-6332-40c3-87c2-080c3e0a6b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677a4995e6e54e80831ed19ab2d687c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving SummaryDoc documents:   0%|          | 0/676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpr = MPRester(api_key)\n",
    "entries = mpr.materials.summary.search(\n",
    "        chemsys=\"O-Li,O-Na,O-K,O-Be,O-Mg,O-Ca,O-Si,O-Al,O-Hf,O-Ti,O-Zr,O-Ga,O-In,O-Zn,O-Ta,O-Ge\",\n",
    "        band_gap=(0.000001,50),\n",
    "        fields=[\"formula_pretty\", \"band_gap\", \"density\", \"formation_energy_per_atom\", \"volume\",\"energy_above_hull\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb7fbcc-5768-4d19-82c4-26282b9f21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('formula_pretty', 'band_gap', 'density', 'formation_energy_per_atom', 'volume','energy_above_hull'))\n",
    "for i, entry in enumerate(entries):\n",
    "    df.loc[i] = [\n",
    "        entry.formula_pretty,\n",
    "        entry.band_gap,\n",
    "        entry.density,\n",
    "        entry.formation_energy_per_atom,\n",
    "        entry.volume,\n",
    "        entry.energy_above_hull\n",
    "    ]\n",
    "stable_df = df.loc[df[\"energy_above_hull\"] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b8b9c2e-d490-4923-a249-41227d4bc541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwisniewski2\\AppData\\Local\\Temp\\ipykernel_17124\\3886056477.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stable_df[\"semiconductor\"] = stable_df['band_gap'].apply(lambda x: 1 if x < 3 and x > 0.5 else 0)\n"
     ]
    }
   ],
   "source": [
    "stable_df[\"semiconductor\"] = stable_df['band_gap'].apply(lambda x: 1 if x < 3 and x > 0.5 else 0)\n",
    "target = \"semiconductor\"\n",
    "predictors = ['density', 'formation_energy_per_atom', 'volume', 'energy_above_hull']\n",
    "X = stable_df[predictors].values\n",
    "y = stable_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03692fe9-7d88-4fe8-9adf-461581ab5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "unique_labels = pd.unique(y)\n",
    "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
    "y = pd.Series(y).map(label_mapping).values\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41b0f5ac-dc07-4b3b-ba25-ba85e047a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = len(torch.unique(y))\n",
    "print(\"Number of classes:\", num_classes) # should be 2 (0 and 1)\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b63581a8-c5d8-4a39-bba3-7798ed9b8b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.3449344635009766\n",
      "Epoch 2/50, Loss: 0.24967649579048157\n",
      "Epoch 3/50, Loss: 0.20486865937709808\n",
      "Epoch 4/50, Loss: 0.31549492478370667\n",
      "Epoch 5/50, Loss: 0.21626673638820648\n",
      "Epoch 6/50, Loss: 0.22689318656921387\n",
      "Epoch 7/50, Loss: 0.16771072149276733\n",
      "Epoch 8/50, Loss: 0.2092466801404953\n",
      "Epoch 9/50, Loss: 0.16498033702373505\n",
      "Epoch 10/50, Loss: 0.2461671382188797\n",
      "Epoch 11/50, Loss: 0.228485107421875\n",
      "Epoch 12/50, Loss: 0.19885089993476868\n",
      "Epoch 13/50, Loss: 0.0990452915430069\n",
      "Epoch 14/50, Loss: 0.1871366649866104\n",
      "Epoch 15/50, Loss: 0.2081928551197052\n",
      "Epoch 16/50, Loss: 0.20718082785606384\n",
      "Epoch 17/50, Loss: 0.06058437004685402\n",
      "Epoch 18/50, Loss: 0.15397939085960388\n",
      "Epoch 19/50, Loss: 0.17496377229690552\n",
      "Epoch 20/50, Loss: 0.1800684928894043\n",
      "Epoch 21/50, Loss: 0.1761961579322815\n",
      "Epoch 22/50, Loss: 0.133975088596344\n",
      "Epoch 23/50, Loss: 0.11070585250854492\n",
      "Epoch 24/50, Loss: 0.12472222000360489\n",
      "Epoch 25/50, Loss: 0.1532943844795227\n",
      "Epoch 26/50, Loss: 0.15572160482406616\n",
      "Epoch 27/50, Loss: 0.05329626053571701\n",
      "Epoch 28/50, Loss: 0.0742398276925087\n",
      "Epoch 29/50, Loss: 0.15761908888816833\n",
      "Epoch 30/50, Loss: 0.17005230486392975\n",
      "Epoch 31/50, Loss: 0.12310287356376648\n",
      "Epoch 32/50, Loss: 0.10704188793897629\n",
      "Epoch 33/50, Loss: 0.08761744946241379\n",
      "Epoch 34/50, Loss: 0.1261352300643921\n",
      "Epoch 35/50, Loss: 0.11847361922264099\n",
      "Epoch 36/50, Loss: 0.2310601770877838\n",
      "Epoch 37/50, Loss: 0.08810608834028244\n",
      "Epoch 38/50, Loss: 0.19508157670497894\n",
      "Epoch 39/50, Loss: 0.18598610162734985\n",
      "Epoch 40/50, Loss: 0.059634286910295486\n",
      "Epoch 41/50, Loss: 0.1482604295015335\n",
      "Epoch 42/50, Loss: 0.08487145602703094\n",
      "Epoch 43/50, Loss: 0.10150409489870071\n",
      "Epoch 44/50, Loss: 0.15414337813854218\n",
      "Epoch 45/50, Loss: 0.16691343486309052\n",
      "Epoch 46/50, Loss: 0.09709856659173965\n",
      "Epoch 47/50, Loss: 0.12034382671117783\n",
      "Epoch 48/50, Loss: 0.04497566446661949\n",
      "Epoch 49/50, Loss: 0.12637843191623688\n",
      "Epoch 50/50, Loss: 0.043502021580934525\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss() # for 0 1 classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "def train_model(num_epochs=50, explicit=True):\n",
    "    for epoch in range(num_epochs):\n",
    "        for features, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if explicit:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "train_model(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ceb0ad3-c43c-4db8-b709-ffb727daa171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.83783783783784%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ead4a7-d78f-4794-970d-d1cacda23f70",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning - grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff5dcada-acee-4691-a4fc-91bf465d50c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 93.24324324324324\n",
      "Best parameters: {'hidden_size': 64, 'learning_rate': 0.1, 'num_epochs': 50, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [64, 128, 256]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_epochs_list = [20, 50, 100]\n",
    "batch_sizes = [64, 128]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        for num_epochs in num_epochs_list:\n",
    "            for batch_size in batch_sizes:\n",
    "                train_dataset = TensorDataset(X_train, y_train)\n",
    "                test_dataset = TensorDataset(X_test, y_test)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "                \n",
    "                input_size = X_train.shape[1]\n",
    "                model = nn.Sequential(\n",
    "                    nn.Linear(input_size, hidden_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_size, num_classes)\n",
    "                )\n",
    "\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                train_model(num_epochs, explicit=False)\n",
    "\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for features, labels in test_loader:\n",
    "                        outputs = model(features)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                accuracy = 100 * correct / total\n",
    "\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = {\n",
    "                        'hidden_size': hidden_size,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'batch_size': batch_size\n",
    "                    }\n",
    "\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941f535-9ac8-4a94-b3a8-134b36e011b0",
   "metadata": {},
   "source": [
    "Better performance, let's try random search.\n",
    "# Hyperparameter tuning - random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c8dec18-ffc2-4b2b-9d24-d9fff1d0ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 94.5945945945946\n",
      "Best parameters: {'hidden_size': 256, 'learning_rate': 0.1, 'num_epochs': 50, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [64, 128, 256]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_epochs_list = [20, 50, 100]\n",
    "batch_sizes = [64, 128]\n",
    "\n",
    "num_samples = 15\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    hidden_size = random.choice(hidden_sizes)\n",
    "    learning_rate = random.choice(learning_rates)\n",
    "    num_epochs = random.choice(num_epochs_list)\n",
    "    batch_size = random.choice(batch_sizes)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, num_classes)\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_model(num_epochs, explicit=False)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = {\n",
    "            'hidden_size': hidden_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "print(\"Best parameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
