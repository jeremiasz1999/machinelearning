{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ad3497-189b-4a49-8bed-061462ad7d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from umap-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from umap-learn) (1.6.0)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.61.2-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from umap-learn) (4.67.1)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
      "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 14.4/30.3 MB 69.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 73.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 64.1 MB/s eta 0:00:00\n",
      "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: llvmlite, numba, pynndescent, umap-learn\n",
      "\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ---------------------------------------- 4/4 [umap-learn]\n",
      "\n",
      "Successfully installed llvmlite-0.44.0 numba-0.61.2 pynndescent-0.5.13 umap-learn-0.5.7\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe60f540-ab0e-456c-817f-baefd7447c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb1b15b-d021-4a17-8324-321f4ae68208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\jeremiasz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38685cb6-e3b3-41d3-923a-2ed59c58b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement rdkit-pypl (from versions: none)\n",
      "ERROR: No matching distribution found for rdkit-pypl\n"
     ]
    }
   ],
   "source": [
    "pip install rdkit-pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bee8178-9b16-4134-a209-783c2c68cda7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataStructs\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFingerprints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FingerprintMols\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chem\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import os \n",
    "\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025cd34-f8a6-45fd-af9d-ebc948a96844",
   "metadata": {},
   "source": [
    "### import the smiles_tg.csv file into a dataframe and identify how many unique smiles strings are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43bc706f-9716-4b36-9502-10cbf760b6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wszystkich wpisów: 966\n",
      "Liczba unikalnych SMILES: 964\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"smiles_tg.csv\")\n",
    "\n",
    "# Pokaż statystyki\n",
    "print(f\"Liczba wszystkich wpisów: {len(df)}\")\n",
    "print(f\"Liczba unikalnych SMILES: {df['SMILES'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caedc7ce-efee-42b6-86fb-fc763e243643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SMILES', 'tg'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a106523-4b57-4533-a204-6e0887f6525a",
   "metadata": {},
   "source": [
    "### drop the duplicate smiles strings in the dataset, keep the first entry and reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdadf2c3-2ad6-4c55-a457-0d492b8075a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba po usunięciu duplikatów: 964\n"
     ]
    }
   ],
   "source": [
    "# Usunięcie duplikatów\n",
    "df_unique = df.drop_duplicates(subset='SMILES', keep='first').reset_index(drop=True)\n",
    "print(f\"Liczba po usunięciu duplikatów: {len(df_unique)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b7ccc-8178-4813-b1ff-246386cb1087",
   "metadata": {},
   "source": [
    "### we are going to use the RDKit library to convert the smiles strings into molecular objects that we will use as features for our models\n",
    "### lets first generate basic descriptors for the molecules\n",
    "### here you will write a basic function called get_basic_descriptors, that takes a smiles string as input, and returns a dictionary of descriptors the descriptors are the following:\n",
    "\n",
    "### 'MW': molecular weight\n",
    " \n",
    "### 'HBD': number of hydrogen bond donors\n",
    "\n",
    "### 'HBA': number of hydrogen bond acceptors\n",
    "\n",
    "### 'TPSA': topological polar surface area\n",
    "\n",
    "### 'Rotatable_Bonds': number of rotatable bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f29225f-f165-4b0b-b47e-efa7245e2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    descriptors = {\n",
    "        'MW': Descriptors.MolWt(mol),\n",
    "        'HBD': rdMolDescriptors.CalcNumHBD(mol),\n",
    "        'HBA': rdMolDescriptors.CalcNumHBA(mol),\n",
    "        'TPSA': rdMolDescriptors.CalcTPSA(mol),\n",
    "        'Rotatable_Bonds': Descriptors.NumRotatableBonds(mol)\n",
    "    }\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3be3bef-e2c0-4408-b84f-f1f137cca1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MW': 46.069, 'HBD': 1, 'HBA': 1, 'TPSA': 20.23, 'Rotatable_Bonds': 0}\n"
     ]
    }
   ],
   "source": [
    "# Przykład\n",
    "example_smiles = \"CCO\"\n",
    "\n",
    "# Oblicz deskryptory\n",
    "desc = get_basic_descriptors(example_smiles)\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc184977-5466-4eca-a8cf-0f89b64cbe72",
   "metadata": {},
   "source": [
    "next create a function called get_morgan_fingerprint that takes in smiles strings and generates morgan fingerprints\n",
    "\n",
    "with a radius of 2 and a length nBits= 1024\n",
    "\n",
    "Return the fingerprint as a list\n",
    "\n",
    "hint: the Input parameters to the function should be\n",
    "\n",
    "smiles, radius, nBits\n",
    "\n",
    "the function should return the fingerprint as a list\n",
    "\n",
    "this can be done in a very few lines of code (don't complicate it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a19cac-7f15-4b30-9874-d9156d516567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rdkit.Chem.rdchem.Mol object at 0x1354dca50>\n",
      "46.069\n"
     ]
    }
   ],
   "source": [
    "# Przykład\n",
    "smiles = \"CCO\"  # etanol\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "print(mol)\n",
    "print(Descriptors.MolWt(mol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca2808-33aa-428c-b011-c22e30881610",
   "metadata": {},
   "source": [
    "next create a function called get_morgan_fingerprint that takes in smiles strings and generates morgan fingerprints\n",
    "\n",
    "with a radius of 2 and a length nBits= 1024\n",
    "\n",
    "Return the fingerprint as a list\n",
    "\n",
    "hint: the Input parameters to the function should be\n",
    "\n",
    "smiles, radius, nBits\n",
    "\n",
    "the function should return the fingerprint as a list\n",
    "\n",
    "this can be done in a very few lines of code (don't complicate it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fca6da19-aa7b-4db8-ab4b-559b60520b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morgan_fingerprint(smiles, radius=2, nBits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(\"Nieprawidłowy SMILES\")\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "    arr = np.zeros((nBits,), dtype=np.int8)  # tworzymy numpy array o długości nBits\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr) # wypełniamy tablicę fingerprintem\n",
    "    return arr.tolist()  # zwracamy jako zwykłą listę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99739d23-f8e2-4aad-9650-97cce1981d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Przykład\n",
    "smiles = \"CC(=O)O\"  # etanol\n",
    "fingerprint = get_morgan_fingerprint(smiles, radius=2, nBits=1024)\n",
    "\n",
    "print(fingerprint[:10])  # pokaż pierwsze 10 bitów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff681027-8a77-45b6-a3cd-93c3ce149259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(get_morgan_fingerprint(\"*c1cccc(-c2nc3ccccc3c(-c3ccc(Oc4ccc(-c5c(-c6ccccc6)c(*)nc6ccccc56)cc4)cc3)c2-c2ccccc2)c1\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b99b11d-a50b-487c-8696-2afae4497690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(get_morgan_fingerprint(\"*Oc1ccc(C2(c3ccc(OC(*)=O)cc3)CC3CCC2C3)cc1\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2791e883-3d72-4910-8389-b241b83915ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(get_morgan_fingerprint(\"*c1cccc(C(=O)c2cccc(N3C(=O)c4ccc(C(c5ccc6c(c5)C(=O)N(*)C6=O)(C(F)(F)F)C(F)(F)F)cc4C3=O)c2)c1\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9930f-4747-406d-9bdd-cada01626452",
   "metadata": {},
   "source": [
    "Next create a function called get_topological_fingerprint that generates topological fingerprints from SMILES strings. These fingerprints capture the 2D structural features of molecules.\n",
    "\n",
    "The function should take in a smiles string and nBits=25\n",
    "\n",
    "return the fingerprint as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f37a0f1b-0c4a-442d-9631-8b1377983280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topological_fingerprint(smiles, nBits=25):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(\"Nieprawidłowy SMILES\")\n",
    "\n",
    "    # Generujemy fingerprint RDKit - domyślnie długość jest 2048 bitów, ale możemy go przyciąć\n",
    "    fp = RDKFingerprint(mol)\n",
    "\n",
    "    # Konwersja fingerprint do numpy array (bit vector)\n",
    "    arr = np.zeros((fp.GetNumBits(),), dtype=int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "\n",
    "    # Przycięcie do nBits (np. 25)\n",
    "    return arr[:nBits].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ace2bbf5-d80e-4569-99ad-4ab229018e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import RDKFingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cb0060e-2145-4896-a40f-c830b3cdd36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "smiles = \"CCO\"  # etanol\n",
    "fingerprint = get_topological_fingerprint(smiles, nBits=25)\n",
    "print(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4f070b1-109d-4e40-a85b-ceea86613850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(get_topological_fingerprint(\"*c1cccc(-c2nc3ccccc3c(-c3ccc(Oc4ccc(-c5c(-c6ccccc6)c(*)nc6ccccc56)cc4)cc3)c2-c2ccccc2)c1\")[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbb2d6-499c-4489-94ad-33e5d8e86e9d",
   "metadata": {},
   "source": [
    "we are now going to use these functions to generate features for our models.\n",
    "\n",
    "lets start with the get_basic_descriptors function, use it to convert the smiles strings in the dataset to features\n",
    "\n",
    "so what you will do here is create a list that contains the descriptors for each smiles string in the dataset\n",
    "\n",
    "remember, in your function, this should return a dictionary of descriptors, so you will have a single list, where each smile string is represented by a dictionary of descriptors\n",
    "\n",
    "if you did this correctly and print the output, the first entry should look similar to this:\n",
    "\n",
    "[{'MW': 167.188, 'HBD': 0, 'HBA': 5, 'TPSA': 75.99, 'Rotatable_Bonds': 0},{.....}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c95a992c-d479-46a7-9e04-89406b62d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [get_basic_descriptors(smiles) for smiles in df_unique['SMILES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ceb54cd-368e-4c76-9e47-11a46c0c5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MW': 494.5880000000004, 'HBD': 2, 'HBA': 6, 'TPSA': 95.12, 'Rotatable_Bonds': 14}\n"
     ]
    }
   ],
   "source": [
    "print(features_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff20f79e-221e-4233-9ff3-b90691815767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MW': 174.15599999999998, 'HBD': 2, 'HBA': 4, 'TPSA': 76.66000000000001, 'Rotatable_Bonds': 5}\n"
     ]
    }
   ],
   "source": [
    "print(features_list[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e27bed73-e863-419d-b490-ff4c81215c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MW': 494.5880000000004, 'HBD': 2, 'HBA': 6, 'TPSA': 95.12, 'Rotatable_Bonds': 14}\n"
     ]
    }
   ],
   "source": [
    "def get_basic_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None  # lub możesz rzucić wyjątek\n",
    "\n",
    "    descriptors = {\n",
    "        'MW': Descriptors.MolWt(mol),\n",
    "        'HBD': Descriptors.NumHDonors(mol),\n",
    "        'HBA': Descriptors.NumHAcceptors(mol),\n",
    "        'TPSA': Descriptors.TPSA(mol),\n",
    "        'Rotatable_Bonds': Descriptors.NumRotatableBonds(mol)\n",
    "    }\n",
    "    return descriptors\n",
    "\n",
    "features_list = [get_basic_descriptors(smiles) for smiles in df_unique['SMILES']]\n",
    "\n",
    "print(features_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335b336-9e5f-417a-bc33-c0f02df7106c",
   "metadata": {},
   "source": [
    "convert this list of dictionaries into a dataframe called df_descriptors\n",
    "\n",
    "next lets scale the features using the StandardScaler from sklearn.preprocessing\n",
    "\n",
    "fit and transform the dataframe and we'll call this scaled dataframe X\n",
    "\n",
    "now that your data is transformed, use KMeans clustering to cluster and fit the scaled dataframe (X).\n",
    "\n",
    "use n_clusters = 5, and a random_state = 0\n",
    "\n",
    "extract the labels using kmeans.labels_ and add this as a column a new column in the df_descriptors called 'cluster'\n",
    "\n",
    "next use the PCA algorithmn to reduce the dimensionality of the dataframe (X) to 2 dimensions\n",
    "\n",
    "Add the the pca1 and pca2 columns to the df_descriptors dataframe\n",
    "\n",
    "finally, use the seaborn library to create a scatter plot\n",
    "\n",
    "set data = descriptors, x = pca1, y = pca2, hue = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ac8f3-7fe9-41fd-9431-11e31986e01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
